{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyXmiJk9Ag9z",
        "outputId": "ba0099e6-819f-4697-c15f-cd8a9e452171"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9da_cw3yt8El",
        "outputId": "7f4006ad-0246-4db2-e2ad-a388172ee15e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 493/263511 [00:19<1:50:10, 39.79it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/1yw53vfQtS.jpg: HTTP Error 400: Bad Request\n",
            "  0%|          | 515/263511 [00:20<2:32:50, 28.68it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/1yw53vfQtS.jpg: HTTP Error 400: Bad Request\n",
            "ERROR:root:Image validation failed for images/train/71yMHX+ppyL.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/1yw53vfQtS.jpg: HTTP Error 400: Bad Request\n",
            "WARNING:root:Placeholder image created at images/train/1yw53vfQtS.jpg\n",
            "  2%|▏         | 5217/263511 [03:07<3:15:12, 22.05it/s]ERROR:root:Image validation failed for images/train/71u-CmBkPoL.jpg: cannot identify image file 'images/train/71u-CmBkPoL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "  3%|▎         | 7669/263511 [04:31<2:25:43, 29.26it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/DzP2RMRQO0.jpg: HTTP Error 400: Bad Request\n",
            "  3%|▎         | 7722/263511 [04:34<3:05:23, 23.00it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/DzP2RMRQO0.jpg: HTTP Error 400: Bad Request\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/DzP2RMRQO0.jpg: HTTP Error 400: Bad Request\n",
            "WARNING:root:Placeholder image created at images/train/DzP2RMRQO0.jpg\n",
            "  4%|▍         | 10038/263511 [05:49<1:42:45, 41.11it/s]ERROR:root:Image validation failed for images/train/71mHbRpZCoL.jpg: image file is truncated (0 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "  6%|▋         | 16662/263511 [09:26<1:40:24, 40.98it/s]ERROR:root:Image validation failed for images/train/7112xy+Bd+L.jpg: image file is truncated (5 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "  7%|▋         | 17187/263511 [09:45<4:11:31, 16.32it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/lwd2cSmT2ux.jpg: HTTP Error 404: Not Found\n",
            "  7%|▋         | 17255/263511 [09:47<2:20:09, 29.28it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/lwd2cSmT2ux.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/lwd2cSmT2ux.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/lwd2cSmT2ux.jpg\n",
            "  7%|▋         | 19391/263511 [10:56<1:38:44, 41.20it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/81GDfkAaFwL.jpg: <urlopen error [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)>\n",
            "  8%|▊         | 20905/263511 [11:48<3:01:34, 22.27it/s]ERROR:root:Image validation failed for images/train/71dCFq+wv1L.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "  8%|▊         | 21718/263511 [12:13<54:14, 74.29it/s]  ERROR:root:Image validation failed for images/train/61Dd8+OloPL.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/61Dd8+OloPL.jpg: image file is truncated (5 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 10%|▉         | 25170/263511 [14:11<3:06:47, 21.27it/s]ERROR:root:Image validation failed for images/train/71HB7jkdrAL.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 10%|▉         | 25354/263511 [14:15<1:10:36, 56.22it/s]ERROR:root:Image validation failed for images/train/81fKMrFdDCL.jpg: image file is truncated (0 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 10%|█         | 26444/263511 [14:52<2:14:31, 29.37it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VCEdbX8DT28.jpg: HTTP Error 404: Not Found\n",
            " 10%|█         | 26474/263511 [14:53<2:10:28, 30.28it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VCEdbX8DT28.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VCEdbX8DT28.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/VCEdbX8DT28.jpg\n",
            " 11%|█         | 27963/263511 [15:42<1:24:02, 46.72it/s]ERROR:root:Image validation failed for images/train/71Ea3whiU9L.jpg: image file is truncated (58 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 11%|█         | 28060/263511 [15:46<2:29:46, 26.20it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/71GRrFElIBL.jpg: <urlopen error [SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)>\n",
            " 11%|█         | 28853/263511 [16:13<2:04:02, 31.53it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/J2DXsUjR8ay.jpg: HTTP Error 404: Not Found\n",
            " 11%|█         | 28900/263511 [16:14<1:09:57, 55.89it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/J2DXsUjR8ay.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/J2DXsUjR8ay.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/J2DXsUjR8ay.jpg\n",
            " 11%|█▏        | 30136/263511 [16:56<1:14:52, 51.94it/s]ERROR:root:Image validation failed for images/train/81c3OTvwhbL.jpg: cannot identify image file 'images/train/81c3OTvwhbL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/81c3OTvwhbL.jpg: image file is truncated (3 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 12%|█▏        | 32781/263511 [18:23<1:08:10, 56.40it/s]ERROR:root:Image validation failed for images/train/51U+wpRpR+L.jpg: image file is truncated (25 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 13%|█▎        | 33260/263511 [18:40<1:31:11, 42.08it/s]ERROR:root:Image validation failed for images/train/61RmFomkUlL.jpg: cannot identify image file 'images/train/61RmFomkUlL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 13%|█▎        | 33752/263511 [18:57<1:37:46, 39.16it/s]ERROR:root:Image validation failed for images/train/71D5iX9sXsL.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/71D5iX9sXsL.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/71D5iX9sXsL.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (2/3)\n",
            " 13%|█▎        | 34838/263511 [19:32<2:23:49, 26.50it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/RBE3EPzT4OZ.jpg: HTTP Error 404: Not Found\n",
            " 13%|█▎        | 34851/263511 [19:32<2:37:26, 24.20it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/RBE3EPzT4OZ.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/RBE3EPzT4OZ.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/RBE3EPzT4OZ.jpg\n",
            " 14%|█▎        | 35961/263511 [20:11<3:24:18, 18.56it/s]ERROR:root:Image validation failed for images/train/616-Bp5N2sL.jpg: image file is truncated (24 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 14%|█▎        | 35976/263511 [20:12<4:13:02, 14.99it/s]ERROR:root:Image validation failed for images/train/616-Bp5N2sL.jpg: image file is truncated (14 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 14%|█▍        | 36974/263511 [20:44<1:27:11, 43.30it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/fUyC7fnSnys.jpg: HTTP Error 404: Not Found\n",
            " 14%|█▍        | 37009/263511 [20:45<2:11:53, 28.62it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/fUyC7fnSnys.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/fUyC7fnSnys.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/fUyC7fnSnys.jpg\n",
            " 15%|█▍        | 38475/263511 [21:34<2:14:22, 27.91it/s]ERROR:root:Image validation failed for images/train/71IzSMu1BVL.jpg: image file is truncated (2 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 15%|█▍        | 38943/263511 [21:48<1:00:22, 61.99it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/9BIu8SYSAek.jpg: HTTP Error 404: Not Found\n",
            " 15%|█▍        | 38979/263511 [21:50<1:43:13, 36.25it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/9BIu8SYSAek.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/9BIu8SYSAek.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/9BIu8SYSAek.jpg\n",
            " 15%|█▌        | 40026/263511 [22:27<1:03:47, 58.39it/s]ERROR:root:Image validation failed for images/train/61w4n6KdVnL.jpg: cannot identify image file 'images/train/61w4n6KdVnL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 15%|█▌        | 40576/263511 [22:46<1:37:27, 38.13it/s]ERROR:root:Image validation failed for images/train/81gJWu6-ngL.jpg: image file is truncated (6 bytes not processed)\n",
            " 15%|█▌        | 40589/263511 [22:47<1:21:12, 45.75it/s]WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 18%|█▊        | 46597/263511 [26:09<1:48:59, 33.17it/s]ERROR:root:Image validation failed for images/train/81auY8SmkJL.jpg: cannot identify image file 'images/train/81auY8SmkJL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 18%|█▊        | 48697/263511 [27:21<2:50:19, 21.02it/s]ERROR:root:Image validation failed for images/train/61ETCAqbhmL.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 20%|█▉        | 51990/263511 [29:11<1:57:59, 29.88it/s]ERROR:root:Image validation failed for images/train/610GTfdbRUL.jpg: image file is truncated (61 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 21%|██        | 54127/263511 [30:20<1:08:33, 50.91it/s]ERROR:root:Image validation failed for images/train/51GMV1Fs6CL.jpg: cannot identify image file 'images/train/51GMV1Fs6CL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 21%|██        | 54156/263511 [30:23<3:51:49, 15.05it/s]ERROR:root:Image validation failed for images/train/61vAxqtYehL.jpg: image file is truncated (0 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 21%|██        | 55157/263511 [30:55<1:27:06, 39.86it/s]ERROR:root:Image validation failed for images/train/61++BPRRoKL.jpg: cannot identify image file 'images/train/61++BPRRoKL.jpg'\n",
            " 21%|██        | 55167/263511 [30:56<1:33:43, 37.05it/s]WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 23%|██▎       | 61480/263511 [34:32<3:23:49, 16.52it/s]ERROR:root:Image validation failed for images/train/61FyTbxajTL.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 24%|██▍       | 63348/263511 [35:36<1:33:29, 35.68it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/H8fMd0pRI6n.jpg: HTTP Error 404: Not Found\n",
            " 24%|██▍       | 63375/263511 [35:37<2:19:13, 23.96it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/H8fMd0pRI6n.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/H8fMd0pRI6n.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/H8fMd0pRI6n.jpg\n",
            " 25%|██▍       | 64995/263511 [36:30<1:41:05, 32.73it/s]ERROR:root:Image validation failed for images/train/515yEK+4-8L.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 25%|██▍       | 65213/263511 [36:39<1:43:58, 31.79it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VjCkaPeR1o.jpg: HTTP Error 400: Bad Request\n",
            " 25%|██▍       | 65268/263511 [36:41<1:17:02, 42.89it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VjCkaPeR1o.jpg: HTTP Error 400: Bad Request\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VjCkaPeR1o.jpg: HTTP Error 400: Bad Request\n",
            "WARNING:root:Placeholder image created at images/train/VjCkaPeR1o.jpg\n",
            " 25%|██▍       | 65685/263511 [36:55<2:39:22, 20.69it/s]ERROR:root:Image validation failed for images/train/71a-afxPj9L.jpg: image file is truncated (3 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 26%|██▌       | 67258/263511 [38:00<1:25:19, 38.33it/s]ERROR:root:Image validation failed for images/train/61IztM8suAL.jpg: image file is truncated (5 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/51s445nzbPL.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/51FG6KaNmNL.jpg: cannot identify image file 'images/train/51FG6KaNmNL.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/81BY4eIEskL.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/61EXWRyRciL.jpg: Remote end closed connection without response\n",
            " 37%|███▋      | 96338/263511 [54:01<19:17, 144.48it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/l8BsJVaKRCe.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/l8BsJVaKRCe.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/l8BsJVaKRCe.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/l8BsJVaKRCe.jpg\n",
            " 39%|███▊      | 101458/263511 [56:56<1:04:30, 41.87it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/PBWKX4CRl2o.jpg: HTTP Error 404: Not Found\n",
            " 39%|███▊      | 101491/263511 [56:57<1:30:23, 29.87it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/PBWKX4CRl2o.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/PBWKX4CRl2o.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/PBWKX4CRl2o.jpg\n",
            " 39%|███▉      | 102633/263511 [57:38<2:35:03, 17.29it/s]ERROR:root:Image validation failed for images/train/61TdxD+qZ9L.jpg: cannot identify image file 'images/train/61TdxD+qZ9L.jpg'\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 39%|███▉      | 103437/263511 [58:06<2:05:42, 21.22it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/3sSrJnc5R58.jpg: HTTP Error 404: Not Found\n",
            " 39%|███▉      | 103491/263511 [58:07<1:08:25, 38.98it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/3sSrJnc5R58.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/3sSrJnc5R58.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/3sSrJnc5R58.jpg\n",
            " 41%|████      | 106733/263511 [1:00:04<1:24:05, 31.07it/s]ERROR:root:Image validation failed for images/train/6198ecSQ1ML.jpg: image file is truncated (37 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 41%|████      | 108186/263511 [1:01:01<1:26:52, 29.80it/s]ERROR:root:Image validation failed for images/train/811AJHJYcBL.jpg: image file is truncated (1 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            "ERROR:root:Image validation failed for images/train/811AJHJYcBL.jpg: image file is truncated (6 bytes not processed)\n",
            "WARNING:root:Invalid image detected, retrying... (1/3)\n",
            " 42%|████▏     | 110842/263511 [1:02:36<1:36:58, 26.24it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/caDEyEaRMCm.jpg: HTTP Error 404: Not Found\n",
            " 42%|████▏     | 110853/263511 [1:02:38<2:18:14, 18.41it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/caDEyEaRMCm.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/caDEyEaRMCm.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/caDEyEaRMCm.jpg\n",
            " 43%|████▎     | 112786/263511 [1:03:49<1:07:00, 37.49it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VRs4UBsSHaM.jpg: HTTP Error 404: Not Found\n",
            " 43%|████▎     | 112815/263511 [1:03:50<1:03:43, 39.41it/s]ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VRs4UBsSHaM.jpg: HTTP Error 404: Not Found\n",
            "ERROR:root:Error downloading image https://m.media-amazon.com/images/I/VRs4UBsSHaM.jpg: HTTP Error 404: Not Found\n",
            "WARNING:root:Placeholder image created at images/train/VRs4UBsSHaM.jpg\n",
            " 44%|████▎     | 115087/263511 [1:05:13<1:24:06, 29.41it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-898e8b9fc503>\u001b[0m in \u001b[0;36m<cell line: 172>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# Load image links from CSV files and download them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mload_and_download_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_images_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;31m# load_and_download_images(test_csv_path, test_images_folder, sample_size=sample_size_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# load_and_download_images(sample_test_csv_path, sample_test_images_folder, sample_size=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-898e8b9fc503>\u001b[0m in \u001b[0;36mload_and_download_images\u001b[0;34m(csv_file_path, download_folder, sample_size)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;31m# Download images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mdownload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_links\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-898e8b9fc503>\u001b[0m in \u001b[0;36mdownload_images\u001b[0;34m(image_links, download_folder, allow_multiprocessing, max_workers)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Limit number of workers to avoid Windows handle limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_image_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_links\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import re\n",
        "import constants\n",
        "import os\n",
        "import pandas as pd\n",
        "import multiprocessing\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from functools import partial\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "import logging\n",
        "\n",
        "# Set up logging for better debugging and monitoring\n",
        "logging.basicConfig(level=logging.WARNING, format='%(asctime)s - %(levelname)s - %(message)s')  # Set logging level to WARNING\n",
        "\n",
        "def common_mistake(unit):\n",
        "    \"\"\"\n",
        "    Corrects common mistakes in units (e.g., different spellings or typos).\n",
        "    \"\"\"\n",
        "    if unit in constants.allowed_units:\n",
        "        return unit\n",
        "    if unit.replace('ter', 'tre') in constants.allowed_units:\n",
        "        return unit.replace('ter', 'tre')\n",
        "    if unit.replace('feet', 'foot') in constants.allowed_units:\n",
        "        return unit.replace('feet', 'foot')\n",
        "    return unit\n",
        "\n",
        "def parse_string(s):\n",
        "    \"\"\"\n",
        "    Parses and validates a prediction string, ensuring it follows the format 'number unit'.\n",
        "    \"\"\"\n",
        "    s_stripped = \"\" if s is None or str(s) == 'nan' else s.strip()\n",
        "    if s_stripped == \"\":\n",
        "        return None, None\n",
        "    pattern = re.compile(r'^-?\\d+(\\.\\d+)?\\s+[a-zA-Z\\s]+$')\n",
        "    if not pattern.match(s_stripped):\n",
        "        raise ValueError(\"Invalid format in {}\".format(s))\n",
        "    parts = s_stripped.split(maxsplit=1)\n",
        "    number = float(parts[0])\n",
        "    unit = common_mistake(parts[1])\n",
        "    if unit not in constants.allowed_units:\n",
        "        raise ValueError(\"Invalid unit [{}] found in {}. Allowed units: {}\".format(\n",
        "            unit, s, constants.allowed_units))\n",
        "    return number, unit\n",
        "\n",
        "def create_placeholder_image(image_save_path):\n",
        "    \"\"\"\n",
        "    Creates a black placeholder image if downloading fails.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        placeholder_image = Image.new('RGB', (100, 100), color='black')\n",
        "        placeholder_image.save(image_save_path)\n",
        "        logging.warning(f\"Placeholder image created at {image_save_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error creating placeholder image: {e}\")\n",
        "\n",
        "def download_image(image_link, save_folder, retries=5, delay=5):\n",
        "    \"\"\"\n",
        "    Downloads an image from a given link. If the download fails after the specified retries,\n",
        "    a placeholder image is created.\n",
        "    \"\"\"\n",
        "    if not isinstance(image_link, str) or not image_link.strip():  # Check for empty or None links\n",
        "        logging.warning(f\"Invalid or empty image link: {image_link}\")\n",
        "        return\n",
        "\n",
        "    filename = Path(image_link).name\n",
        "    image_save_path = os.path.join(save_folder, filename)\n",
        "\n",
        "    if os.path.exists(image_save_path):\n",
        "        return  # Skip logging for existing images\n",
        "\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            urllib.request.urlretrieve(image_link, image_save_path)  # Correct use of urllib.request\n",
        "            if validate_image(image_save_path):\n",
        "                logging.info(f\"Image successfully downloaded: {image_save_path}\")\n",
        "                return\n",
        "            else:\n",
        "                logging.warning(f\"Invalid image detected, retrying... ({attempt + 1}/{retries})\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error downloading image {image_link}: {e}\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "    # logging.error(f\"Failed to download image after {retries} retries: {image_link}\")\n",
        "    create_placeholder_image(image_save_path)  # Create a black placeholder image for invalid links/images\n",
        "\n",
        "def validate_image(image_path):\n",
        "    \"\"\"\n",
        "    Checks if the downloaded image is valid and not corrupted.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if the image is valid, False otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            img.verify()  # Verify that it is an image\n",
        "        # Reload the image to check if it can be converted to an array (optional, can be skipped)\n",
        "        img = Image.open(image_path)\n",
        "        img.load()\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Image validation failed for {image_path}: {e}\")\n",
        "        return False\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocesses the image for model prediction.\n",
        "    Includes resizing, normalization, etc.\n",
        "\n",
        "    Args:\n",
        "    - image_path (str): Path to the image.\n",
        "    - target_size (tuple): Target size for resizing (width, height).\n",
        "\n",
        "    Returns:\n",
        "    - np.array: Preprocessed image ready for prediction.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')  # Convert to RGB\n",
        "        img = img.resize(target_size)\n",
        "        img = np.array(img) / 255.0  # Normalize pixel values to [0, 1]\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error preprocessing image {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def download_images(image_links, download_folder, allow_multiprocessing=True, max_workers=20):\n",
        "    \"\"\"\n",
        "    Downloads multiple images using multiprocessing for efficiency.\n",
        "    Adjusts the number of workers to avoid Windows handle limitations.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    if allow_multiprocessing:\n",
        "        download_image_partial = partial(\n",
        "            download_image, save_folder=download_folder, retries=3, delay=3)\n",
        "\n",
        "        with multiprocessing.Pool(min(max_workers, 20)) as pool:  # Limit number of workers to avoid Windows handle limits\n",
        "            list(tqdm(pool.imap(download_image_partial, image_links), total=len(image_links)))\n",
        "            pool.close()\n",
        "            pool.join()\n",
        "    else:\n",
        "        for image_link in tqdm(image_links, total=len(image_links)):\n",
        "            download_image(image_link, save_folder=download_folder, retries=2, delay=2)\n",
        "\n",
        "def load_and_download_images(csv_file_path, download_folder, sample_size=None):\n",
        "    \"\"\"\n",
        "    Loads image links from a CSV file, samples a subset, and downloads them to the specified folder.\n",
        "\n",
        "    Args:\n",
        "    - csv_file_path (str): Path to the CSV file containing image links.\n",
        "    - download_folder (str): Folder to download images to.\n",
        "    - sample_size (int, optional): Number of samples to use for testing. Default is None (use full dataset).\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_file_path, on_bad_lines='skip')\n",
        "    if sample_size is not None:\n",
        "        df = df.sample(n=sample_size, random_state=42)  # Sample a subset for quick testing\n",
        "    image_links = df['image_link'].tolist()\n",
        "\n",
        "    # Ensure the folder exists\n",
        "    if not os.path.exists(download_folder):\n",
        "        os.makedirs(download_folder)\n",
        "\n",
        "    # Download images\n",
        "    download_images(image_links, download_folder)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage: download images from train and test datasets with sampling\n",
        "    train_csv_path = 'dataset/cleaned_train2.csv'\n",
        "    test_csv_path = 'dataset/test.csv'\n",
        "    sample_test_csv_path = 'dataset/sample_test.csv'\n",
        "    train_images_folder = 'images/train'\n",
        "    sample_test_images_folder = 'images/sample_test'\n",
        "    test_images_folder = 'images/test'\n",
        "\n",
        "    # Download a small subset of images for testing\n",
        "    sample_size_train = None\n",
        "    sample_size_test = None\n",
        "\n",
        "    # Load image links from CSV files and download them\n",
        "    load_and_download_images(train_csv_path, train_images_folder, sample_size=sample_size_train)\n",
        "    # load_and_download_images(test_csv_path, test_images_folder, sample_size=sample_size_test)\n",
        "    # load_and_download_images(sample_test_csv_path, sample_test_images_folder, sample_size=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Conv2D, MaxPooling2D, Reshape, Bidirectional, Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urlparse\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Set up paths\n",
        "TRAIN_CSV_PATH = 'dataset/cleaned_train2.csv'\n",
        "TEST_CSV_PATH = 'dataset/test.csv'\n",
        "TRAIN_IMAGES_DIR = 'images/train'\n",
        "TEST_IMAGES_DIR = 'images/test'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/Model/ocr_model.h5'\n",
        "OUTPUT_CSV_PATH = '/content/drive/MyDrive/Model/test_out.csv'\n",
        "\n",
        "# Set constants\n",
        "IMAGE_SIZE = 250  # Maximum size for any dimension\n",
        "MAX_TEXT_LENGTH = 35  # Adjust based on your data\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "SAMPLE_SIZE = 50000  # Number of samples to use for initial training; set to None to use the full dataset\n",
        "\n",
        "# Load entity-unit mappings with abbreviations and plural forms\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon',\n",
        "                    'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}\n",
        "\n",
        "# Allowed characters for OCR predictions (including digits and units)\n",
        "ALLOWED_CHARACTERS = string.digits + \" \" + \"\".join(set().union(*entity_unit_map.values()))\n",
        "\n",
        "# Function to extract the image filename from the image link\n",
        "def get_image_filename(image_link):\n",
        "    parsed_url = urlparse(image_link)\n",
        "    return os.path.basename(parsed_url.path)\n",
        "\n",
        "# Function to preprocess images with aspect ratio preservation and padding\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "    # Resize while keeping aspect ratio\n",
        "    img.thumbnail((IMAGE_SIZE, IMAGE_SIZE), Image.LANCZOS)\n",
        "\n",
        "    # Create a new square image with a black background\n",
        "    new_img = Image.new('L', (IMAGE_SIZE, IMAGE_SIZE), color=0)\n",
        "\n",
        "    # Paste the resized image onto the center of the new square image\n",
        "    new_img.paste(img, ((IMAGE_SIZE - img.width) // 2, (IMAGE_SIZE - img.height) // 2))\n",
        "\n",
        "    img = np.array(new_img) / 255.0  # Normalize to [0, 1]\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "    return img\n",
        "\n",
        "# Load training data\n",
        "def load_data(csv_path, images_dir, sample_size=None):\n",
        "    df = pd.read_csv(csv_path, on_bad_lines='skip')  # Skips bad lines\n",
        "\n",
        "    # Use only a subset of the data if sample_size is specified\n",
        "    if sample_size is not None:\n",
        "        df = df.sample(n=sample_size, random_state=42)  # Randomly sample data for initial training\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        image_path = os.path.join(images_dir, get_image_filename(row['image_link']))\n",
        "        if os.path.exists(image_path):\n",
        "            try:\n",
        "                img = preprocess_image(image_path)\n",
        "                images.append(img)\n",
        "                labels.append(encode_text(row['entity_value']))  # Encode labels\n",
        "            except (OSError, IOError) as e:\n",
        "                # Skip images that are truncated or have issues\n",
        "                print(f\"Skipping file {image_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Encode text into numerical representation for training\n",
        "def encode_text(text):\n",
        "    try:\n",
        "        number, unit = text.split()\n",
        "        unit_index = list(entity_unit_map.keys()).index(unit)\n",
        "        # Return a one-hot encoded vector for the unit and number\n",
        "        one_hot = np.zeros(len(entity_unit_map.keys()))\n",
        "        one_hot[unit_index] = 1\n",
        "        return [float(number)] + one_hot.tolist()\n",
        "    except (ValueError, IndexError) as e:\n",
        "        # If parsing fails, return zeros\n",
        "        return [0.0] + [0] * len(entity_unit_map.keys())\n",
        "\n",
        "# Decode numerical representation back to text\n",
        "def decode_text(prediction):\n",
        "    # If prediction is a 1D array, reshape it to 2D for consistent processing\n",
        "    if len(prediction.shape) == 1:\n",
        "        prediction = np.expand_dims(prediction, axis=0)\n",
        "\n",
        "    if len(prediction[0]) == 1 + len(entity_unit_map.keys()):  # Ensure the prediction length is valid\n",
        "        number = prediction[0][0]  # Get the predicted number\n",
        "        unit_idx = np.argmax(prediction[0][1:])  # Get the index of the predicted unit\n",
        "        unit = list(entity_unit_map.keys())[unit_idx]  # Map the index back to the unit\n",
        "        return f\"{number:.2f} {unit}\"\n",
        "    else:\n",
        "        return \"\"  # Return empty if the prediction is invalid\n",
        "\n",
        "# Define the model architecture using CRNN (Convolutional Recurrent Neural Network)\n",
        "def build_crnn_model(input_shape):\n",
        "    input_img = Input(shape=input_shape, name='image_input')\n",
        "\n",
        "    # Convolutional layers\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Reshape the output to 3D for LSTM layers\n",
        "    time_steps, features = x.shape[1] * x.shape[2], x.shape[3]\n",
        "    x = Reshape(target_shape=(time_steps, features))(x)\n",
        "\n",
        "    # Recurrent layers\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(128, return_sequences=False))(x)\n",
        "\n",
        "    # Fully connected layer for regression (first output is the number, the rest are the one-hot encoded unit vectors)\n",
        "    output = Dense(1 + len(entity_unit_map.keys()), activation='linear')(x)\n",
        "\n",
        "    model = Model(inputs=input_img, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Custom loss function for regression\n",
        "def custom_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "# Compile and train the model\n",
        "def train_model(model, train_images, train_labels, val_images, val_labels):\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=custom_loss, metrics=['mae'])\n",
        "\n",
        "    # Save the best model based on validation loss\n",
        "    checkpoint = ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "    # Reduce learning rate when a metric has stopped improving\n",
        "    lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, min_lr=1e-6, verbose=1)\n",
        "\n",
        "    # Using data augmentation to improve generalization\n",
        "    train_datagen = ImageDataGenerator(rotation_range=2, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.01, zoom_range=[0.9, 1.25])\n",
        "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    # Fit the model with data augmentation for training set and rescaling for validation set\n",
        "    model.fit(\n",
        "        train_datagen.flow(train_images, train_labels, batch_size=BATCH_SIZE),\n",
        "        validation_data=val_datagen.flow(val_images, val_labels, batch_size=BATCH_SIZE),\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[checkpoint, lr_reduction]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    images, labels = load_data(TRAIN_CSV_PATH, TRAIN_IMAGES_DIR, sample_size=SAMPLE_SIZE)\n",
        "\n",
        "    # Split into training and validation sets\n",
        "    train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "    input_shape = (IMAGE_SIZE, IMAGE_SIZE, 1)\n",
        "\n",
        "    # Build, train, and evaluate model\n",
        "    model = build_crnn_model(input_shape)\n",
        "    model = train_model(model, train_images, train_labels, val_images, val_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-rInPmBuDH0",
        "outputId": "ed05ad3c-ea5b-413e-baa3-e8b677e374ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 9769/50000 [01:09<03:50, 174.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping file images/train/71Z8jYq8OLL.jpg: cannot identify image file '/content/images/train/71Z8jYq8OLL.jpg'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▍     | 22389/50000 [02:39<03:48, 120.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping file images/train/81S2Z43PCvL.jpg: cannot identify image file '/content/images/train/81S2Z43PCvL.jpg'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [05:50<00:00, 142.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.1037e-04 - mae: 0.0050\n",
            "Epoch 1: val_loss improved from inf to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "84/84 [==============================] - 565s 7s/step - loss: 1.1037e-04 - mae: 0.0050 - val_loss: 2.8611e-06 - val_mae: 0.0014 - lr: 1.0000e-04\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "84/84 [==============================] - ETA: 0s - loss: 2.5269e-06 - mae: 9.6979e-04\n",
            "Epoch 2: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "84/84 [==============================] - 561s 7s/step - loss: 2.5269e-06 - mae: 9.6979e-04 - val_loss: 2.7077e-07 - val_mae: 4.2875e-04 - lr: 1.0000e-04\n",
            "Epoch 3/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.5777e-06 - mae: 7.4001e-04\n",
            "Epoch 3: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "84/84 [==============================] - 561s 7s/step - loss: 1.5777e-06 - mae: 7.4001e-04 - val_loss: 5.9052e-08 - val_mae: 1.8119e-04 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.2405e-06 - mae: 6.6032e-04\n",
            "Epoch 4: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "84/84 [==============================] - 562s 7s/step - loss: 1.2405e-06 - mae: 6.6032e-04 - val_loss: 3.7513e-08 - val_mae: 1.3041e-04 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 1.0228e-06 - mae: 5.9855e-04\n",
            "Epoch 5: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "84/84 [==============================] - 563s 7s/step - loss: 1.0228e-06 - mae: 5.9855e-04 - val_loss: 3.3179e-08 - val_mae: 1.4559e-04 - lr: 5.0000e-05\n",
            "Epoch 6/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 9.4458e-07 - mae: 5.6894e-04\n",
            "Epoch 6: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 562s 7s/step - loss: 9.4458e-07 - mae: 5.6894e-04 - val_loss: 3.8272e-08 - val_mae: 1.5993e-04 - lr: 5.0000e-05\n",
            "Epoch 7/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 8.5500e-07 - mae: 5.4301e-04\n",
            "Epoch 7: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "84/84 [==============================] - 562s 7s/step - loss: 8.5500e-07 - mae: 5.4301e-04 - val_loss: 2.6014e-08 - val_mae: 1.2978e-04 - lr: 5.0000e-05\n",
            "Epoch 8/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 7.9654e-07 - mae: 5.2005e-04\n",
            "Epoch 8: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 562s 7s/step - loss: 7.9654e-07 - mae: 5.2005e-04 - val_loss: 2.6132e-08 - val_mae: 1.2920e-04 - lr: 2.5000e-05\n",
            "Epoch 9/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 7.3495e-07 - mae: 5.0383e-04\n",
            "Epoch 9: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 561s 7s/step - loss: 7.3495e-07 - mae: 5.0383e-04 - val_loss: 3.0059e-08 - val_mae: 1.3763e-04 - lr: 2.5000e-05\n",
            "Epoch 10/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 7.1270e-07 - mae: 4.9344e-04\n",
            "Epoch 10: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "84/84 [==============================] - 561s 7s/step - loss: 7.1270e-07 - mae: 4.9344e-04 - val_loss: 2.3400e-08 - val_mae: 1.1751e-04 - lr: 2.5000e-05\n",
            "Epoch 11/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.8951e-07 - mae: 4.8613e-04\n",
            "Epoch 11: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "84/84 [==============================] - 561s 7s/step - loss: 6.8951e-07 - mae: 4.8613e-04 - val_loss: 2.1239e-08 - val_mae: 1.1473e-04 - lr: 1.2500e-05\n",
            "Epoch 12/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.9436e-07 - mae: 4.8498e-04\n",
            "Epoch 12: val_loss improved from 0.00000 to 0.00000, saving model to /content/drive/MyDrive/Model/ocr_model.h5\n",
            "84/84 [==============================] - 561s 7s/step - loss: 6.9436e-07 - mae: 4.8498e-04 - val_loss: 1.7138e-08 - val_mae: 1.0745e-04 - lr: 1.2500e-05\n",
            "Epoch 13/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.7343e-07 - mae: 4.7715e-04\n",
            "Epoch 13: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "84/84 [==============================] - 561s 7s/step - loss: 6.7343e-07 - mae: 4.7715e-04 - val_loss: 2.2935e-08 - val_mae: 1.2219e-04 - lr: 1.2500e-05\n",
            "Epoch 14/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.4672e-07 - mae: 4.6535e-04\n",
            "Epoch 14: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 563s 7s/step - loss: 6.4672e-07 - mae: 4.6535e-04 - val_loss: 2.1582e-08 - val_mae: 1.2092e-04 - lr: 6.2500e-06\n",
            "Epoch 15/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.2854e-07 - mae: 4.6161e-04\n",
            "Epoch 15: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 562s 7s/step - loss: 6.2854e-07 - mae: 4.6161e-04 - val_loss: 1.8832e-08 - val_mae: 1.1081e-04 - lr: 6.2500e-06\n",
            "Epoch 16/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.3055e-07 - mae: 4.6170e-04\n",
            "Epoch 16: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "84/84 [==============================] - 562s 7s/step - loss: 6.3055e-07 - mae: 4.6170e-04 - val_loss: 1.8325e-08 - val_mae: 1.0751e-04 - lr: 6.2500e-06\n",
            "Epoch 17/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.3992e-07 - mae: 4.6379e-04\n",
            "Epoch 17: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 564s 7s/step - loss: 6.3992e-07 - mae: 4.6379e-04 - val_loss: 1.7797e-08 - val_mae: 1.0491e-04 - lr: 3.1250e-06\n",
            "Epoch 18/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.2772e-07 - mae: 4.5886e-04\n",
            "Epoch 18: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 561s 7s/step - loss: 6.2772e-07 - mae: 4.5886e-04 - val_loss: 1.8906e-08 - val_mae: 1.0863e-04 - lr: 3.1250e-06\n",
            "Epoch 19/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.3299e-07 - mae: 4.5804e-04\n",
            "Epoch 19: val_loss did not improve from 0.00000\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "84/84 [==============================] - 563s 7s/step - loss: 6.3299e-07 - mae: 4.5804e-04 - val_loss: 1.8561e-08 - val_mae: 1.0948e-04 - lr: 3.1250e-06\n",
            "Epoch 20/20\n",
            "84/84 [==============================] - ETA: 0s - loss: 6.3878e-07 - mae: 4.6551e-04\n",
            "Epoch 20: val_loss did not improve from 0.00000\n",
            "84/84 [==============================] - 561s 7s/step - loss: 6.3878e-07 - mae: 4.6551e-04 - val_loss: 1.8593e-08 - val_mae: 1.0710e-04 - lr: 1.5625e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model and Calculate F1 Score\n",
        "def evaluate_model(model, val_images, val_labels):\n",
        "    predictions = model.predict(val_images)\n",
        "    predicted_texts = [decode_text(pred) for pred in predictions]\n",
        "\n",
        "    # Convert true labels to their original format\n",
        "    true_texts = [decode_text(true) for true in val_labels]\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    f1 = f1_score(true_texts, predicted_texts, average='weighted', zero_division=1)\n",
        "    precision = precision_score(true_texts, predicted_texts, average='weighted', zero_division=1)\n",
        "    recall = recall_score(true_texts, predicted_texts, average='weighted', zero_division=1)\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Evaluate the model and calculate F1 score\n",
        "evaluate_model(model, val_images, val_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "77Qe7V8IuFi6",
        "outputId": "d4c05722-3b1f-4478-ff93-42016610ee22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ad3281b3e0fa>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Evaluate the model and calculate F1 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "from urllib.parse import urlparse\n",
        "import string\n",
        "\n",
        "# Load entity-unit mappings with abbreviations and plural forms\n",
        "entity_unit_map = {\n",
        "    'width': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'depth': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'height': {'centimetre', 'foot', 'inch', 'metre', 'millimetre', 'yard'},\n",
        "    'item_weight': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'maximum_weight_recommendation': {'gram', 'kilogram', 'microgram', 'milligram', 'ounce', 'pound', 'ton'},\n",
        "    'voltage': {'kilovolt', 'millivolt', 'volt'},\n",
        "    'wattage': {'kilowatt', 'watt'},\n",
        "    'item_volume': {'centilitre', 'cubic foot', 'cubic inch', 'cup', 'decilitre', 'fluid ounce', 'gallon',\n",
        "                    'imperial gallon', 'litre', 'microlitre', 'millilitre', 'pint', 'quart'}\n",
        "}\n",
        "\n",
        "# Function to extract the image filename from the image link\n",
        "def get_image_filename(image_link):\n",
        "    parsed_url = urlparse(image_link)\n",
        "    return os.path.basename(parsed_url.path)\n",
        "\n",
        "# Function to preprocess images with aspect ratio preservation and padding\n",
        "def preprocess_image(image_path, image_size=250):\n",
        "    img = Image.open(image_path).convert('L')  # Convert to grayscale\n",
        "\n",
        "    # Resize while keeping aspect ratio\n",
        "    img.thumbnail((image_size, image_size), Image.LANCZOS)\n",
        "\n",
        "    # Create a new square image with a black background\n",
        "    new_img = Image.new('L', (image_size, image_size), color=0)\n",
        "\n",
        "    # Paste the resized image onto the center of the new square image\n",
        "    new_img.paste(img, ((image_size - img.width) // 2, (image_size - img.height) // 2))\n",
        "\n",
        "    img = np.array(new_img) / 255.0  # Normalize to [0, 1]\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "    return img\n",
        "\n",
        "# Encode text into numerical representation for training\n",
        "def encode_text(text):\n",
        "    try:\n",
        "        number, unit = text.split()\n",
        "        unit_index = list(entity_unit_map.keys()).index(unit)\n",
        "        # Return a one-hot encoded vector for the unit and number\n",
        "        one_hot = np.zeros(len(entity_unit_map.keys()))\n",
        "        one_hot[unit_index] = 1\n",
        "        return [float(number)] + one_hot.tolist()\n",
        "    except (ValueError, IndexError) as e:\n",
        "        # If parsing fails, return zeros\n",
        "        return [0.0] + [0] * len(entity_unit_map.keys())\n",
        "\n",
        "# Decode numerical representation back to text\n",
        "def decode_text(prediction):\n",
        "    # If prediction is a 1D array, reshape it to 2D for consistent processing\n",
        "    if len(prediction.shape) == 1:\n",
        "        prediction = np.expand_dims(prediction, axis=0)\n",
        "\n",
        "    if len(prediction[0]) == 1 + len(entity_unit_map.keys()):  # Ensure the prediction length is valid\n",
        "        number = prediction[0][0]  # Get the predicted number\n",
        "        unit_idx = np.argmax(prediction[0][1:])  # Get the index of the predicted unit\n",
        "        unit = list(entity_unit_map.keys())[unit_idx]  # Map the index back to the unit\n",
        "        return f\"{number:.2f} {unit}\"\n",
        "    else:\n",
        "        return \"\"  # Return empty if the prediction is invalid\n",
        "\n",
        "# Load test data\n",
        "def load_test_data(csv_path, images_dir, start_index=0, num_files=50):\n",
        "    df = pd.read_csv(csv_path, on_bad_lines='skip')\n",
        "    df = df.iloc[start_index:start_index + num_files]  # Select the specified range\n",
        "\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        image_path = os.path.join(images_dir, get_image_filename(row['image_link']))\n",
        "        if os.path.exists(image_path):\n",
        "            try:\n",
        "                img = preprocess_image(image_path)\n",
        "                images.append(img)\n",
        "                labels.append(encode_text(row['entity_value']))  # Encode labels\n",
        "            except (OSError, IOError) as e:\n",
        "                # Skip images that are truncated or have issues\n",
        "                print(f\"Skipping file {image_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Evaluate Model and Calculate F1 Score\n",
        "def evaluate_model(model_path, csv_path, images_dir, start_index=0, num_files=50):\n",
        "    # Load model\n",
        "    model = load_model(model_path, compile=False)\n",
        "\n",
        "    # Load test data\n",
        "    val_images, val_labels = load_test_data(csv_path, images_dir, start_index, num_files)\n",
        "\n",
        "    # Predict on test data\n",
        "    predictions = model.predict(val_images)\n",
        "    predicted_texts = [decode_text(pred) for pred in predictions]\n",
        "\n",
        "    # Convert true labels to their original format\n",
        "    true_texts = [decode_text(true) for true in val_labels]\n",
        "\n",
        "    # Calculate F1 Score\n",
        "    f1 = f1_score(true_texts, predicted_texts, average='weighted', zero_division=1)\n",
        "    precision = precision_score(true_texts, predicted_texts, average='weighted', zero_division=1)\n",
        "    recall = recall_score(true_texts, predicted_texts, average='weighted', zero_division=1)\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = '/content/drive/MyDrive/Model/ocr_model50k-20.h5'  # Path to your saved model\n",
        "    csv_path = 'dataset/cleaned_train2.csv'  # Path to the CSV file\n",
        "    images_dir = 'images/train'  # Directory containing images\n",
        "    start_index = 110000  # Starting index of the CSV data to test\n",
        "    num_files = 1000  # Number of files to test\n",
        "\n",
        "    evaluate_model(model_path, csv_path, images_dir, start_index, num_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sxI2qhiQtZFz",
        "outputId": "c7e10d6c-f52f-4d83-a8db-8e0a837d258a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to LSTM: {'time_major': False}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-62ad67845c55>\u001b[0m in \u001b[0;36m<cell line: 120>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mnum_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m  \u001b[0;31m# Number of files to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-62ad67845c55>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_path, csv_path, images_dir, start_index, num_files)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Load test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         return legacy_h5_format.load_model_from_hdf5(\n\u001b[0m\u001b[1;32m    190\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/legacy_h5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msaving_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras_option_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_legacy_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             model = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/model.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional_from_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             return functional_from_config(\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Legacy format deserialization (no \"module\" key)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# used for H5 and SavedModel formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             layer = saving_utils.model_from_config(\n\u001b[0m\u001b[1;32m    458\u001b[0m                 \u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_replace_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keras.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     return serialization.deserialize_keras_object(\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMODULE_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/legacy/saving/serialization.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"custom_objects\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                 deserialized_obj = cls.from_config(\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0mcls_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                     custom_objects={\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/bidirectional.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         config[\"layer\"] = serialization_lib.deserialize_keras_object(\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/serialization_lib.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcustom_obj_scope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe_mode_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m             \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/lstm.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, dropout, recurrent_dropout, seed, return_sequences, return_state, go_backwards, stateful, unroll, use_cudnn, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mimplementation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"implementation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         )\n\u001b[0;32m--> 486\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, zero_output_for_mask, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0;34mf\"Received: cell={cell}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# If True, the output for masked timestep will be zeros, whereas in the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to LSTM: {'time_major': False}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict and generate the output for the test dataset\n",
        "def predict_and_generate_output(model, test_csv_path, images_dir, output_csv_path):\n",
        "    test_df = pd.read_csv(test_csv_path)\n",
        "    results = []\n",
        "\n",
        "    for _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
        "        image_path = os.path.join(images_dir, get_image_filename(row['image_link']))\n",
        "        if os.path.exists(image_path):\n",
        "            img = preprocess_image(image_path)\n",
        "            prediction = model.predict(np.expand_dims(img, axis=0))\n",
        "            decoded_text = decode_text(prediction[0])  # Decode prediction to text\n",
        "            results.append((row['index'], decoded_text))\n",
        "        else:\n",
        "            results.append((row['index'], \"\"))\n",
        "\n",
        "    # Save predictions to CSV\n",
        "    pd.DataFrame(results, columns=['index', 'prediction']).to_csv(output_csv_path, index=False)\n",
        "\n",
        "# Predict on test images and generate the output CSV file\n",
        "predict_and_generate_output(model, TEST_CSV_PATH, TEST_IMAGES_DIR, OUTPUT_CSV_PATH)\n"
      ],
      "metadata": {
        "id": "HImXJml2uLd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}